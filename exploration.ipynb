{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Born in Iran'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/oshus/code/gsu/csc4780/project/exploration.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/oshus/code/gsu/csc4780/project/exploration.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(df[desc_features], df[\u001b[39m'\u001b[39m\u001b[39mmatch\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m.25\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/oshus/code/gsu/csc4780/project/exploration.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m my_tree \u001b[39m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/oshus/code/gsu/csc4780/project/exploration.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m my_tree\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/oshus/code/gsu/csc4780/project/exploration.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m y_pred \u001b[39m=\u001b[39m my_tree\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/oshus/code/gsu/csc4780/project/exploration.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m acc \u001b[39m=\u001b[39m my_tree\u001b[39m.\u001b[39mscore(x_test,y_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    938\u001b[0m         X,\n\u001b[1;32m    939\u001b[0m         y,\n\u001b[1;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    163\u001b[0m check_X_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mDTYPE, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m check_y_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 165\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    166\u001b[0m     X, y, validate_separately\u001b[39m=\u001b[39;49m(check_X_params, check_y_params)\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    169\u001b[0m     X\u001b[39m.\u001b[39msort_indices()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39mif\u001b[39;00m validate_separately:\n\u001b[1;32m    573\u001b[0m     \u001b[39m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     \u001b[39m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[39m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     \u001b[39m# :(\u001b[39;00m\n\u001b[1;32m    577\u001b[0m     check_X_params, check_y_params \u001b[39m=\u001b[39m validate_separately\n\u001b[0;32m--> 578\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_X_params)\n\u001b[1;32m    579\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:2072\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2072\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Born in Iran'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn import tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df = pd.read_csv('data/speed_dating_raw.csv', encoding='latin-1')\n",
    "\n",
    "# features = set(df.columns)\n",
    "# features.remove('match')\n",
    "# desc_features = list(features)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df[desc_features], df['match'], test_size=.25, random_state=25)\n",
    "\n",
    "\n",
    "# my_tree = DecisionTreeClassifier(max_depth=2)\n",
    "# my_tree.fit(x_train, y_train)\n",
    "# y_pred = my_tree.predict(x_test)\n",
    "# acc = my_tree.score(x_test,y_test)\n",
    "# print(\"Error: \", 1 - acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from geopy.geocoders import Nominatim\n",
    "# import math\n",
    "import numpy as np\n",
    "\n",
    "cols = ['match', 'exphappy', 'samerace', 'hobby_diff_phys', 'hobby_diff_out', 'hobby_diff_in', 'same_goal', 'attr_diff', 'sinc_diff', 'intel_diff', 'fun_diff', 'amb_diff', 'income_diff', 'age_diff', 'same_career', 'confidence', 'imprace', 'date_freq', 'out_freq']\n",
    "raw_df = pd.read_csv('data/speed_dating_raw.csv', encoding='latin-1')\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "hobbies = ['sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga']\n",
    "\n",
    "hobbies_phys = ['sports', 'exercise', 'hiking', 'yoga']\n",
    "hobbies_out = ['dining', 'museums', 'concerts', 'clubbing', 'theater', 'movies', 'shopping']\n",
    "hobbies_in = ['tvsports', 'art', 'gaming', 'reading', 'tv', 'music']\n",
    "\n",
    "atts = ['attr', 'sinc', 'intel', 'fun', 'amb']\n",
    "lookingfor = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1']\n",
    "selfrate_a = ['attr3_1', 'sinc3_1', 'intel3_1', 'fun3_1', 'amb3_1']\n",
    "selfrate_b = ['attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1']\n",
    "\n",
    "def sum_diff(attrs,p_1,p_2):\n",
    "    hobby_diff = 0\n",
    "    for h in attrs:\n",
    "        hobby_diff += abs(p_1[h] - p_2[h])\n",
    "    return hobby_diff\n",
    "\n",
    "def att_diff(p_1, p_2):\n",
    "    all_diff = {}\n",
    "    for i in range(5):\n",
    "        diff = 0\n",
    "        selfrate_a1 = p_1[selfrate_a[i]]\n",
    "        selfrate_b1 = p_1[selfrate_b[i]]\n",
    "        selfrate_a2 = p_2[selfrate_a[i]]\n",
    "        selfrate_b2 = p_2[selfrate_b[i]]\n",
    "\n",
    "        # if pd.isna(p_1[selfrate_a[i]]) and pd.isna(p_1[selfrate_b[i]]):\n",
    "        #     selfrate_a1 = raw_df[selfrate_a[i]].mean()\n",
    "        #     selfrate_b1 = raw_df[selfrate_b[i]].mean()\n",
    "        if pd.isna(p_1[selfrate_a[i]]):\n",
    "            selfrate_a1 = p_1[selfrate_b[i]]\n",
    "        elif pd.isna(p_1[selfrate_b[i]]):\n",
    "            selfrate_b1 = p_1[selfrate_a[i]]\n",
    "        # if pd.isna(p_2[selfrate_a[i]]) and pd.isna(p_2[selfrate_b[i]]):\n",
    "        #     selfrate_a2 = raw_df[selfrate_a[i]].mean()\n",
    "        #     selfrate_b2 = raw_df[selfrate_b[i]].mean()\n",
    "        if pd.isna(p_2[selfrate_a[i]]):\n",
    "            selfrate_a2 = p_2[selfrate_b[i]]\n",
    "        elif pd.isna(p_2[selfrate_b[i]]):\n",
    "            selfrate_b2 = p_2[selfrate_a[i]]\n",
    "\n",
    "        want_1 = p_1[lookingfor[i]]\n",
    "        want_2 = p_2[lookingfor[i]]\n",
    "        selfrate_1 = (selfrate_a1 + selfrate_b1) / 2\n",
    "        selfrate_2 = (selfrate_a2 + selfrate_b2) / 2\n",
    "        diff += abs(selfrate_1 - want_2)\n",
    "        diff += abs(selfrate_2 - want_1)\n",
    "        if pd.isna(p_1[lookingfor[i]]) and pd.isna(p_2[lookingfor[i]]): print('W')\n",
    "        all_diff[atts[i]] = diff\n",
    "    return all_diff\n",
    "\n",
    "def plain_diff(key, p_1, p_2):\n",
    "    item_1 = p_1[key]\n",
    "    item_2 = p_2[key]\n",
    "    if isinstance(item_1,str):\n",
    "        item_1 = float(item_1.replace(',',''))\n",
    "    if isinstance(item_2,str):\n",
    "        item_2 = float(item_2.replace(',',''))\n",
    "    if pd.isna(p_1[key]) or pd.isna(p_2[key]):\n",
    "        return np.nan\n",
    "    return abs(item_1 - item_2)\n",
    "\n",
    "def dated(iid, pid):\n",
    "    return len(raw_df.loc[(raw_df['iid'] == iid) & (raw_df['pid'] == pid)]) != 0\n",
    "\n",
    "# def get_dist(p_1,p_2):\n",
    "#     if isinstance(p_1['zipcode'], str):\n",
    "#         zip_1 = int(p_1['zipcode'].replace(',',''))\n",
    "#     else:\n",
    "#         zip_1 = p_1['zipcode']\n",
    "#     if isinstance(p_2['zipcode'], str):\n",
    "#         zip_2 = int(p_2['zipcode'].replace(',',''))\n",
    "#     else:\n",
    "#         zip_2 = p_2['zipcode']\n",
    "#     if pd.isna(zip_1) or pd.isna(zip_2) or (zip_1 == 0) or (zip_2 == 0):\n",
    "#         return np.nan\n",
    "#     geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "#     l_1 = geolocator.geocode(zip_1)\n",
    "#     l_2 = geolocator.geocode(zip_2)\n",
    "#     d = math.sqrt(((l_1.latitude - l_2.latitude) ** 2) + ((l_1.longitude - l_2.longitude) ** 2))\n",
    "#     return d\n",
    "\n",
    "def create_df():\n",
    "    for iid in range(1,len(raw_df['iid'].unique())+1):\n",
    "        for pid in raw_df.loc[raw_df['iid'] == iid]['pid'].unique():\n",
    "            if dated(iid,pid):\n",
    "                date = raw_df.loc[(raw_df['iid'] == iid) & (raw_df['pid'] == pid)].to_dict('records')[0]\n",
    "                p_1 = raw_df.loc[raw_df['iid'] == iid].to_dict('records')[0]\n",
    "                p_2 = raw_df.loc[raw_df['iid'] == pid].to_dict('records')[0]\n",
    "                att_diffs = att_diff(p_1, p_2)\n",
    "                # print(date['wave'],att_diffs)\n",
    "\n",
    "                new_row = {\n",
    "                    'match': date['match'],\n",
    "                    'exphappy': date['exphappy'],\n",
    "                    'samerace': date['samerace'],\n",
    "                    'hobby_diff_phys': sum_diff(hobbies_phys,p_1,p_2),\n",
    "                    'hobby_diff_out': sum_diff(hobbies_out, p_1, p_2),\n",
    "                    'hobby_diff_in': sum_diff(hobbies_in, p_1, p_2),\n",
    "                    'same_goal': int(p_1['goal'] == p_2['goal']),\n",
    "                    'attr_diff': att_diffs['attr'],\n",
    "                    'sinc_diff': att_diffs['sinc'],\n",
    "                    'intel_diff': att_diffs['intel'],\n",
    "                    'fun_diff': att_diffs['fun'],\n",
    "                    'amb_diff': att_diffs['amb'],\n",
    "                    'income_diff': plain_diff('income', p_1, p_2),\n",
    "                    'age_diff': plain_diff('age', p_1, p_2),\n",
    "                    'same_career': int(p_1['career_c'] == p_2['career_c']),\n",
    "                    'confidence': ((((int(p_1['expnum']) / 20) + (int(p_2['expnum']) / 20)) / 2) if not (pd.isna(p_1['expnum']) or pd.isna(p_2['expnum'])) else p_1['expnum']),\n",
    "                    'imprace': (((p_1['imprace'] + p_2['imprace']) / 2) if not (pd.isna(p_1['imprace']) or pd.isna(p_2['imprace'])) else p_1['imprace']),\n",
    "                    'date_freq': p_1['date'],\n",
    "                    'out_freq': p_1['go_out']\n",
    "                }\n",
    "                # print(new_row)\n",
    "                df.loc[len(df)] = new_row\n",
    "    return df\n",
    "\n",
    "df = create_df()\n",
    "df.to_csv('data/speed_dating.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
